# Mini V2X Performance & Edge Connectivity Testbed

**A containerized, web-controlled simulation environment for testing Vehicle-to-Infrastructure (V2I) communication performance without expensive real-world deployments.**

## Purpose & Impact

### What It Does
This testbed **simulates and measures** the performance of connected vehicle communication between:
- **Vehicle Node** (On-Board Unit simulator) â†’ Sends telemetry & safety messages
- **Edge Server** (Roadside Unit/Infrastructure) â†’ Receives and analyzes messages

### Why It Matters
**Traditional V2X testing requires:**
- Expensive roadside infrastructure ($10K-$100K per RSU)
- Real vehicles with OBUs
- Physical test tracks or roads
- Significant setup and logistics time

**This testbed provides:**
- âœ… **$0 infrastructure cost** - Runs on any Linux machine with Docker
- âœ… **Instant setup** - Deploy in 5 minutes
- âœ… **Repeatable tests** - Exact network conditions, no environmental variance
- âœ… **Safe experimentation** - Test extreme conditions (severe packet loss, high latency)
- âœ… **Educational tool** - Learn V2X concepts without real equipment

### Who It's For
- **Researchers** - Protocol comparison, network optimization studies
- **Educators** - Teaching V2X communication concepts
- **V2X Developers** - Testing applications before field deployment
- **Network Planners** - Modeling edge infrastructure requirements

### Real-World Applications
- **5G V2X Research**: Test MEC (Multi-access Edge Computing) latency requirements
- **Safety Message Delivery**: Validate critical alert transmission under poor network conditions
- **Protocol Selection**: Compare UDP, TCP, and MQTT for different V2X use cases
- **Network Capacity Planning**: Determine infrastructure needs before deployment
- **ML/AI Training**: Generate labeled datasets for predictive models

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Your Linux Machine                      â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Vehicle Node â”‚ â”€â”€â”€â”€â”€â”€â†’ â”‚ Edge Server  â”‚              â”‚
â”‚  â”‚  (Sender)    â”‚  UDP/   â”‚ (Receiver)   â”‚              â”‚
â”‚  â”‚              â”‚  TCP/   â”‚              â”‚              â”‚
â”‚  â”‚ Simulates:   â”‚  MQTT   â”‚ Simulates:   â”‚              â”‚
â”‚  â”‚ â€¢ OBU        â”‚         â”‚ â€¢ RSU        â”‚              â”‚
â”‚  â”‚ â€¢ Telemetry  â”‚         â”‚ â€¢ MEC Node   â”‚              â”‚
â”‚  â”‚ â€¢ Safety     â”‚         â”‚ â€¢ 5G Edge    â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                   â”‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Network Simulation (tc)                   â”‚  â”‚
â”‚  â”‚  â€¢ Delay (0-300ms)                                â”‚  â”‚
â”‚  â”‚  â€¢ Packet Loss (0-30%)                            â”‚  â”‚
â”‚  â”‚  â€¢ Bandwidth Limits (2-15 Mbps)                   â”‚  â”‚
â”‚  â”‚  â€¢ Jitter, Reordering                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Web Dashboard (http://localhost:8501)          â”‚  â”‚
â”‚  â”‚  â€¢ Run experiments from browser                   â”‚  â”‚
â”‚  â”‚  â€¢ Real-time metrics & charts                     â”‚  â”‚
â”‚  â”‚  â€¢ Historical results viewer                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What Gets Tested
âœ… **End-to-End Latency** - Time from vehicle send â†’ infrastructure receive
âœ… **Packet Loss** - Message delivery reliability under degradation
âœ… **Throughput** - Message rate and bandwidth utilization
âœ… **Protocol Performance** - UDP vs TCP vs MQTT comparison
âœ… **Network Resilience** - Behavior during cell handoffs
âœ… **Jitter** - Variance in latency (critical for safety messages)

### What It Does NOT Test
âŒ **Vehicle-to-Vehicle (V2V)** - Only tests Vehicle-to-Infrastructure (V2I)
âŒ **Real RF propagation** - Network simulation via software (tc), not radio
âŒ **GPS accuracy** - Simulated vehicle position
âŒ **Real-time OS** - Uses standard Linux, not automotive RTOS

## Features

- **UI-Based Test Control**: Run experiments directly from the dashboard - no CLI required
- **Multi-Protocol Support**: UDP, TCP, and MQTT
- **Network Simulation**: Linux `tc` traffic shaping (delay, jitter, packet loss, bandwidth limits)
- **Real-Time Metrics**: Latency, jitter, packet loss, throughput
- **Real-Time Progress Tracking**: Monitor running experiments with live phase indicators
- **Packet Capture**: tcpdump integration with PCAP analysis
- **Analytics Pipeline**: KPI calculation and visualization
- **Live Dashboard**: Streamlit-based real-time monitoring with multi-page navigation
- **Results Viewer**: Browse historical experiments and download reports
- **ML Extension**: Predictive models for performance degradation

## Prerequisites

- Linux system (Ubuntu 20.04+ recommended)
- Docker and Docker Compose
- Root access (for network shaping with `tc`)
- 4GB+ RAM recommended

## Quick Start

### 1. Clone Repository

```bash
cd mini-v2x-testbed
```

### 2. Build and Start Services

```bash
docker-compose up --build
```

This starts:
- MQTT Broker (port 1883)
- Edge Server (port 5000)
- Vehicle Node (sending messages)
- Dashboard (http://localhost:8501)

### 3. Access Dashboard

Open your browser to:
```
http://localhost:8501
```

You'll see:
- **Main Dashboard**: Real-time metrics and visualizations
- **ğŸ® Test Control Center**: Run experiments from the UI
- **ğŸ“ˆ Results Viewer**: Browse completed experiments

## Running Experiments

### Method 1: UI-Based Control (Recommended - No CLI Required!)

The easiest way to run experiments is through the **Test Control Center**:

1. **Open Dashboard**: Navigate to http://localhost:8501
2. **Click "ğŸ® Test Control Center"** (top navigation or sidebar)
3. **Configure Experiment**:
   - Enter experiment name (or use auto-generated)
   - Set duration (10-300 seconds)
   - Select network profile (normal/moderate/severe/handoff)
   - Choose protocols to test
4. **Click "ğŸš€ Start Experiment"**
5. **Monitor Progress**: Watch real-time progress bar and phase indicators
6. **View Results**: Automatically displayed when complete, or browse via "ğŸ“ˆ Results Viewer"

**Features:**
- âœ… No command-line interaction needed
- âœ… Real-time progress tracking with phase indicators
- âœ… Automatic analytics generation
- âœ… Browse historical experiments
- âœ… Download reports (JSON, CSV, PCAP)
- âœ… One-click result viewing
- âœ… Queue management (one test at a time)

### Method 2: Automated Script (CLI)

For automation or CI/CD integration, use the experiment runner script:

```bash
# Make script executable (first time only)
chmod +x run_experiment.sh

# Run experiment: ./run_experiment.sh <name> <duration> <profile>
sudo ./run_experiment.sh my_test 60 moderate
```

This will:
1. Start all services
2. Clear existing data
3. Apply network profile
4. Start packet capture
5. Run for specified duration
6. Generate analytics and visualizations
7. Clean up and save results to `outputs/my_test/`

**Output includes:**
- `kpi_report.json` - Complete metrics
- `messages.csv` - Raw data
- `*.png` - Visualization charts
- `capture.pcap` - Packet capture
- `pcap_analysis.json` - Network analysis

### Method 3: Manual Step-by-Step (Advanced)

For maximum control, run each step manually:

1. **Start the testbed**:
   ```bash
   docker-compose up -d
   ```

2. **Apply network degradation** (requires root):
   ```bash
   sudo bash network_profiles/moderate.sh
   ```

3. **Capture packets**:
   ```bash
   sudo tcpdump -i eth0 port 5000 -w pcaps/experiment_$(date +%s).pcap
   ```

4. **Run for desired duration** (e.g., 60 seconds):
   ```bash
   sleep 60
   ```

5. **Stop packet capture**: `Ctrl+C`

6. **Clear network shaping**:
   ```bash
   sudo bash network_profiles/clear.sh
   ```

7. **Generate analytics**:
   ```bash
   docker-compose run --rm analytics python kpi_calculator.py /data/v2x_testbed.db /outputs
   docker-compose run --rm analytics python visualize.py /data/v2x_testbed.db /outputs
   ```

8. **View results**: Check `./outputs/` directory

### Network Profiles

Apply different network conditions:

```bash
# Normal (no degradation)
sudo bash network_profiles/normal.sh

# Moderate congestion (50ms delay, 1% loss)
sudo bash network_profiles/moderate.sh

# Severe degradation (200ms delay, 10% loss)
sudo bash network_profiles/severe.sh

# Handoff scenario (simulates cell tower handoff)
sudo bash network_profiles/handoff.sh

# Clear all rules
sudo bash network_profiles/clear.sh
```

### Changing Protocol

Edit `vehicle_node/config.yaml`:

```yaml
vehicle:
  protocol: "TCP"  # Options: UDP, TCP, MQTT
```

Then restart:
```bash
docker-compose restart vehicle_node
```

## Control Center UI Guide

### Overview

The Control Center provides a complete web-based interface for managing experiments without touching the command line.

### Test Control Page

**Access:** http://localhost:8501 â†’ Click "ğŸ® Test Control Center"

**Features:**

1. **Experiment Configuration**
   - **Name**: Auto-generated or custom (alphanumeric + underscores only)
   - **Duration**: 10-300 seconds slider
   - **Network Profile**: Dropdown selection
     - Normal: Baseline (no degradation)
     - Moderate: 50ms delay, 1% loss
     - Severe: 200ms delay, 10% loss
     - Handoff: Multi-phase cell tower handoff simulation
   - **Protocols**: Multi-select (UDP/TCP/MQTT)
   - **Advanced Options**: Coming soon (custom delay/loss, PCAP control)

2. **Active Experiment Monitor**
   - Real-time progress bar (0-100%)
   - Current phase indicator:
     - ğŸ”„ Initializing
     - ğŸš€ Starting services
     - ğŸ§¹ Clearing data
     - ğŸŒ Applying network profile
     - ğŸ“¦ Capturing packets
     - âš¡ Running experiment
     - ğŸ›‘ Stopping capture
     - ğŸ“Š Analyzing results
     - ğŸ“ˆ Parsing PCAP
     - âœ… Completed
   - Elapsed and remaining time
   - Cancel button (graceful shutdown)

3. **Recent Experiments List**
   - Status badges (Running, Completed, Failed, Cancelled)
   - Filter by status
   - Quick "View Results" button
   - Error details for failed experiments

### Results Viewer Page

**Access:** http://localhost:8501 â†’ Click "ğŸ“ˆ Results Viewer"

**Features:**

1. **Experiment Selector**
   - Dropdown of all completed experiments
   - Shows name, profile, and timestamp

2. **Performance Metrics Dashboard**
   - **Latency**: Avg, Median, P95, P99, Min, Max, StdDev, Jitter
   - **Reliability**: Packet loss rate, total lost packets
   - **Throughput**: Messages/sec, Bytes/sec, Kbps, Mbps
   - **Protocol Comparison**: Side-by-side table

3. **Visualizations**
   - Latency over time
   - Latency distribution
   - Protocol comparison charts
   - Message type comparison
   - Packet loss over time

4. **Download Options**
   - ğŸ“„ JSON Report - Full KPI metrics
   - ğŸ“Š CSV Data - Raw message data
   - ğŸ“¦ PCAP File - Network packet capture

5. **Coming Soon**
   - Multi-experiment comparison
   - Statistical significance testing
   - Export to PDF reports

### Queue Management

**Important:** Only one experiment can run at a time to prevent:
- Network profile conflicts (multiple tc rules)
- PCAP file collisions
- Resource contention

If you try to start a second experiment while one is running:
- âŒ Request blocked with clear message
- â„¹ï¸ Shows which experiment is currently running
- ğŸ’¡ Suggests waiting for completion

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit Dashboard (Port 8501)   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Metrics  â”‚  â”‚Test Control  â”‚    â”‚
â”‚  â”‚Dashboard â”‚  â”‚   Center     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Results Viewer             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  TestOrchestrator    â”‚
    â”‚  (test_runner.py)    â”‚
    â”‚  - Subprocess mgmt   â”‚
    â”‚  - Progress tracking â”‚
    â”‚  - State management  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚run_experimentâ”‚    â”‚experiment_runsâ”‚
â”‚.sh script   â”‚    â”‚table (SQLite)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Database Tables

**New table:** `experiment_runs`
- Tracks all experiments (pending, running, completed, failed, cancelled)
- Stores configuration, progress, timestamps, error messages
- Enables historical browsing and state recovery

**Existing tables:**
- `messages` - Message data with latency metrics
- `network_conditions` - Applied network profiles
- `pcap_sessions` - Packet capture metadata

## Analytics

### Generate KPI Report

```bash
docker-compose run --rm analytics python kpi_calculator.py /data/v2x_testbed.db /outputs
```

Outputs:
- `outputs/kpi_report.json` - Full KPI report
- `outputs/messages.csv` - Raw message data
- `outputs/latency_by_protocol.csv` - Latency summary

### Generate Visualizations

```bash
docker-compose run --rm analytics python visualize.py /data/v2x_testbed.db /outputs
```

Generates:
- `latency_over_time.png`
- `latency_distribution.png`
- `protocol_comparison.png`
- `message_type_comparison.png`
- `packet_loss_over_time.png`

### Parse PCAP Files

```bash
docker-compose run --rm analytics python parser.py /pcaps/experiment_*.pcap /outputs/pcap_analysis.json
```

## ML Extension (Optional)

### Train Prediction Models

```bash
docker-compose run --rm analytics python /app/ml_extension/train_model.py /data/v2x_testbed.db
```

Outputs:
- `outputs/latency_model.pkl` - Latency prediction model
- `outputs/loss_model.pkl` - Packet loss classifier

### Make Predictions

```python
from ml_extension.predict import V2XPredictor

predictor = V2XPredictor('/outputs')
predicted_latency = predictor.predict_latency(
    protocol='UDP',
    message_type='telemetry',
    latency_rolling_mean=25.0,
    latency_rolling_std=5.0,
    hour=14,
    minute=30
)
```

## Key Performance Indicators (KPIs)

### Latency
- **Average Latency**: Mean end-to-end latency
- **P95 Latency**: 95th percentile (excludes outliers)
- **P99 Latency**: 99th percentile (worst-case scenarios)

**Calculation**: `receive_timestamp - send_timestamp`

### Jitter
- **Definition**: Variance in latency
- **Calculation**: Standard deviation of inter-arrival times

### Packet Loss
- **Detection**: Sequence gap tracking
- **Calculation**: `(total_gaps / total_expected) * 100`

### Throughput
- **Messages/sec**: `total_messages / time_span`
- **Bytes/sec**: `total_bytes / time_span`
- **Kbps**: `(bytes_per_sec * 8) / 1000`

## Repository Structure

```
mini-v2x-testbed/
â”œâ”€â”€ vehicle_node/          # OBU simulator
â”‚   â”œâ”€â”€ sender.py
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ edge_server/           # Message receiver
â”‚   â”œâ”€â”€ receiver.py
â”‚   â”œâ”€â”€ database.py        # UPDATED: Added experiment_runs table
â”‚   â”œâ”€â”€ metrics.py
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ network_profiles/      # Traffic shaping scripts
â”‚   â”œâ”€â”€ normal.sh
â”‚   â”œâ”€â”€ moderate.sh
â”‚   â”œâ”€â”€ severe.sh
â”‚   â”œâ”€â”€ handoff.sh
â”‚   â””â”€â”€ clear.sh
â”œâ”€â”€ analytics/             # KPI calculation & visualization
â”‚   â”œâ”€â”€ kpi_calculator.py
â”‚   â”œâ”€â”€ visualize.py
â”‚   â”œâ”€â”€ parser.py
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ dashboard/             # Streamlit dashboard (ENHANCED)
â”‚   â”œâ”€â”€ app.py             # UPDATED: Added navigation
â”‚   â”œâ”€â”€ test_runner.py     # NEW: Test orchestration
â”‚   â”œâ”€â”€ pages/             # NEW: Multi-page app
â”‚   â”‚   â”œâ”€â”€ 1_ğŸ®_Test_Control.py   # NEW: Control center UI
â”‚   â”‚   â””â”€â”€ 2_ğŸ“ˆ_Results_Viewer.py # NEW: Results browser
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile         # UPDATED: System dependencies
â”œâ”€â”€ ml_extension/          # ML prediction models
â”‚   â”œâ”€â”€ train_model.py
â”‚   â””â”€â”€ predict.py
â”œâ”€â”€ data/                  # Database storage
â”‚   â””â”€â”€ v2x_testbed.db     # UPDATED: New experiment_runs table
â”œâ”€â”€ outputs/               # Analysis results (per experiment)
â”‚   â””â”€â”€ <experiment_name>/
â”‚       â”œâ”€â”€ kpi_report.json
â”‚       â”œâ”€â”€ messages.csv
â”‚       â”œâ”€â”€ *.png
â”‚       â””â”€â”€ capture.pcap
â”œâ”€â”€ run_experiment.sh      # UPDATED: Progress markers added
â”œâ”€â”€ docker-compose.yml     # UPDATED: Dashboard with NET_ADMIN
â””â”€â”€ README.md              # UPDATED: Control center docs
```

**Key Changes:**
- âœ¨ `dashboard/test_runner.py` - New test orchestration engine
- âœ¨ `dashboard/pages/` - Multi-page Streamlit app structure
- ğŸ”§ `edge_server/database.py` - Extended with experiment tracking
- ğŸ”§ `run_experiment.sh` - Instrumented with progress markers
- ğŸ”§ `docker-compose.yml` - Dashboard with NET_ADMIN capability

## Network Shaping Details

### Moderate Profile
- Delay: 50ms Â± 10ms
- Packet Loss: 1%
- Bandwidth: 10-15 Mbit/s

### Severe Profile
- Delay: 200ms Â± 50ms
- Packet Loss: 10% (25% correlation)
- Bandwidth: 2-5 Mbit/s
- Reordering: 5%

### Handoff Scenario
- **Phase 1** (2s): Normal (30ms, 0.5% loss)
- **Phase 2** (3s): Disruption (300ms, 30% loss)
- **Phase 3** (2s): Recovery (50ms, 2% loss)
- **Phase 4**: Stabilized (25ms, 0.5% loss)

## Troubleshooting

### Control Center Issues

#### "Experiment blocked - another test is running"
- Only one experiment can run at a time
- Wait for current test to complete (check progress bar)
- Or cancel the running experiment (use ğŸ›‘ Cancel button)

#### Experiment stuck at a phase
1. Check dashboard container logs:
   ```bash
   docker-compose logs -f dashboard
   ```
2. Look for error messages in the experiment list (Failed status)
3. Cancel and retry
4. Verify network profiles cleared: `sudo bash network_profiles/clear.sh`

#### Progress bar not updating
- Refresh browser (F5)
- Check if experiment process is still running:
  ```bash
  docker-compose exec dashboard ps aux | grep run_experiment
  ```
- Dashboard auto-refreshes every 2 seconds during tests

#### Results not appearing
- Wait 30 seconds after completion for analytics generation
- Check outputs directory exists:
  ```bash
  ls -la outputs/<experiment_name>/
  ```
- Verify analytics container ran:
  ```bash
  docker-compose logs analytics
  ```

#### "Permission denied" for network profiles
- Dashboard container needs NET_ADMIN capability
- Check docker-compose.yml has `cap_add: [NET_ADMIN]`
- Rebuild dashboard:
  ```bash
  docker-compose build dashboard
  docker-compose up -d dashboard
  ```

### General Issues

#### Permission denied when running tc scripts (CLI method)
```bash
# Run with sudo
sudo bash network_profiles/moderate.sh
```

#### No data in dashboard
- Ensure vehicle_node and edge_server are running
- Check logs: `docker-compose logs -f edge_server`
- Verify database: `sqlite3 data/v2x_testbed.db "SELECT COUNT(*) FROM messages;"`
- Restart vehicle node: `docker-compose restart vehicle_node`

#### High packet loss with normal profile
- Clear existing tc rules: `sudo bash network_profiles/clear.sh`
- Check network interface: Ensure scripts use correct interface (default: eth0)

#### Container networking issues
- Verify network: `docker network inspect mini-v2x-testbed_v2x_network`
- Restart services: `docker-compose restart`

#### Dashboard pages not showing (404)
- Ensure pages directory exists: `dashboard/pages/`
- Rebuild dashboard: `docker-compose build dashboard`
- Check that both page files exist:
  - `1_ğŸ®_Test_Control.py`
  - `2_ğŸ“ˆ_Results_Viewer.py`

## References

- **V2X Communication**: 3GPP TS 23.285
- **Linux Traffic Control**: `man tc-netem`
- **PCAP Analysis**: Wireshark documentation

## Contributing

Contributions welcome! Focus areas:
- Additional network profiles
- Enhanced ML models
- Real vehicle data integration
- 5G NR simulation

## License

MIT License - See LICENSE file

## Acknowledgments

Built for V2X research and education. Not intended for production deployment.
